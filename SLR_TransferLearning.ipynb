{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths - Update these paths to your local dataset paths\n",
    "isl_path = r\"ISL_Dataset\"\n",
    "mnist_train_path = r\"sign_mnist_train.csv\"\n",
    "mnist_test_path = r\"sign_mnist_test.csv\"\n",
    "asl_path = r\"asl_alphabet_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ISL dataset function\n",
    "def load_isl_dataset(isl_path):\n",
    "    images_data = []\n",
    "    labels = []\n",
    "    for label in os.listdir(isl_path):\n",
    "        label_folder = os.path.join(isl_path, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for img_file in os.listdir(label_folder):\n",
    "                img_path = os.path.join(label_folder, img_file)\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    with Image.open(img_path) as img:\n",
    "                        img = img.convert('L')  # Convert to grayscale\n",
    "                        img = img.resize((28, 28))\n",
    "                        img_array = np.array(img).flatten()\n",
    "                        images_data.append(img_array)\n",
    "                        labels.append(label)\n",
    "    return np.array(images_data), np.array(labels)\n",
    "\n",
    "# Load ISL dataset\n",
    "isl_images, isl_labels = load_isl_dataset(isl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess MNIST dataset\n",
    "mnist_train = pd.read_csv(mnist_train_path)\n",
    "mnist_test = pd.read_csv(mnist_test_path)\n",
    "mnist_labels = mnist_train['label'].values\n",
    "mnist_train.drop('label', axis=1, inplace=True)\n",
    "mnist_images = np.array([np.reshape(i, (28, 28)) for i in mnist_train.values])\n",
    "mnist_images = mnist_images.reshape(mnist_images.shape[0], 28, 28, 1)\n",
    "\n",
    "# Reshape ISL images to match MNIST dimensions\n",
    "isl_images = isl_images.reshape(isl_images.shape[0], 28, 28, 1)\n",
    "\n",
    "# Combine MNIST and ISL datasets\n",
    "combined_images = np.concatenate((mnist_images, isl_images), axis=0)\n",
    "combined_labels = np.concatenate((mnist_labels, isl_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\A\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\B\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\C\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\D\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\E\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\F\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\G\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\H\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\I\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\J\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\K\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\L\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\M\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\N\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\O\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\P\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\Q\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\R\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\S\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\T\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\U\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\V\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\W\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\X\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\Y\n",
      "Permission denied for file: asl_alphabet_train\\asl_alphabet_train\\Z\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load ASL dataset function\n",
    "def load_asl_dataset(asl_path):\n",
    "    asl_images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Traverse each label folder inside the main ASL dataset directory\n",
    "    for label in os.listdir(asl_path):\n",
    "        folder_path = os.path.join(asl_path, label)\n",
    "        \n",
    "        # Check if the current item is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for img_file in os.listdir(folder_path):\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                \n",
    "                # Load the image and handle exceptions\n",
    "                try:\n",
    "                    img = image.load_img(img_path, target_size=(28, 28), color_mode=\"grayscale\")\n",
    "                    img_array = image.img_to_array(img) / 255.0  # Normalize pixel values\n",
    "                    asl_images.append(img_array)\n",
    "                    labels.append(label)\n",
    "                except UnidentifiedImageError:\n",
    "                    print(f\"Could not process file: {img_file}\")\n",
    "                except PermissionError:\n",
    "                    print(f\"Permission denied for file: {img_path}\")\n",
    "    \n",
    "    return np.array(asl_images), np.array(labels)\n",
    "\n",
    "# Load ASL dataset\n",
    "asl_images, asl_labels = load_asl_dataset(asl_path)\n",
    "asl_images = asl_images.reshape(asl_images.shape[0], 28, 28, 1)  # Reshape for CNN input\n",
    "\n",
    "print(\"Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ASL, ISL, and MNIST datasets\n",
    "combined_images = np.concatenate((combined_images, asl_images), axis=0)\n",
    "combined_labels = np.concatenate((combined_labels, asl_labels), axis=0)\n",
    "\n",
    "# Transform labels to binary representation\n",
    "label_binarizer = LabelBinarizer()\n",
    "combined_labels = label_binarizer.fit_transform(combined_labels)\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(combined_images, combined_labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.06 GiB for an array with shape (19709, 96, 96, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Preprocess input data to match MobileNetV2 dimensions\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m x_train_resized \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m x_test_resized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([cv2\u001b[38;5;241m.\u001b[39mresize(cv2\u001b[38;5;241m.\u001b[39mmerge([img] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m), (\u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m x_test])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Add custom layers on top of MobileNetV2\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.06 GiB for an array with shape (19709, 96, 96, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV2 model\n",
    "mobilenet = MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Preprocess input data to match MobileNetV2 dimensions\n",
    "x_train_resized = np.array([cv2.resize(cv2.merge([img] * 3), (96, 96)) for img in x_train])\n",
    "x_test_resized = np.array([cv2.resize(cv2.merge([img] * 3), (96, 96)) for img in x_test])\n",
    "\n",
    "# Add custom layers on top of MobileNetV2\n",
    "model = Sequential([\n",
    "    mobilenet,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_binarizer.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(datagen.flow(x_train_resized, y_train, batch_size=64), validation_data=(x_test_resized, y_test),\n",
    "                    epochs=10, callbacks=[reduce_lr, early_stopping])\n",
    "\n",
    "# Save model\n",
    "model.save(\"combined_sign_language_mobilenet.h5\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37428\\3388854190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "y_pred = model.predict(x_test_resized)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred_classes))\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
